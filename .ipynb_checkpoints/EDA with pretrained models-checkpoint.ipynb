{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "#img load\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from fake_useragent import UserAgent \n",
    "\n",
    "#img preprocessing\n",
    "from keras.preprocessing import image\n",
    "from keras.applications import mobilenet_v2\n",
    "\n",
    "\n",
    "#show img\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "#remove warnings\n",
    "import tensorflow as tf\n",
    "# tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "# color distributions\n",
    "# import os\n",
    "# os.environ['OPENCV_IO_MAX_IMAGE_PIXELS']=str(2**64)\n",
    "import cv2\n",
    "import imutils\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load link dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_link_df = pd.read_pickle('attractions_img_links_df.pkl')\n",
    "att_loc_df = pd.read_pickle('attractions_loc_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1233 entries, Barber Vintage Motorsports Museum to Antler Arches of Jackson\n",
      "Data columns (total 58 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       1233 non-null   object\n",
      " 1   1       1233 non-null   object\n",
      " 2   2       1233 non-null   object\n",
      " 3   3       1233 non-null   object\n",
      " 4   4       1233 non-null   object\n",
      " 5   5       1233 non-null   object\n",
      " 6   6       1233 non-null   object\n",
      " 7   7       1233 non-null   object\n",
      " 8   8       1233 non-null   object\n",
      " 9   9       1233 non-null   object\n",
      " 10  10      1233 non-null   object\n",
      " 11  11      1233 non-null   object\n",
      " 12  12      1233 non-null   object\n",
      " 13  13      1233 non-null   object\n",
      " 14  14      1233 non-null   object\n",
      " 15  15      1233 non-null   object\n",
      " 16  16      1233 non-null   object\n",
      " 17  17      1233 non-null   object\n",
      " 18  18      1233 non-null   object\n",
      " 19  19      1233 non-null   object\n",
      " 20  20      1233 non-null   object\n",
      " 21  21      1233 non-null   object\n",
      " 22  22      1233 non-null   object\n",
      " 23  23      1233 non-null   object\n",
      " 24  24      1233 non-null   object\n",
      " 25  25      1233 non-null   object\n",
      " 26  26      1233 non-null   object\n",
      " 27  27      1233 non-null   object\n",
      " 28  28      1233 non-null   object\n",
      " 29  29      1233 non-null   object\n",
      " 30  30      1233 non-null   object\n",
      " 31  31      1233 non-null   object\n",
      " 32  32      1233 non-null   object\n",
      " 33  33      1233 non-null   object\n",
      " 34  34      1233 non-null   object\n",
      " 35  35      1233 non-null   object\n",
      " 36  36      1233 non-null   object\n",
      " 37  37      1233 non-null   object\n",
      " 38  38      1233 non-null   object\n",
      " 39  39      1233 non-null   object\n",
      " 40  40      1233 non-null   object\n",
      " 41  41      1233 non-null   object\n",
      " 42  42      1233 non-null   object\n",
      " 43  43      1233 non-null   object\n",
      " 44  44      1233 non-null   object\n",
      " 45  45      1233 non-null   object\n",
      " 46  46      1233 non-null   object\n",
      " 47  47      1233 non-null   object\n",
      " 48  48      1233 non-null   object\n",
      " 49  49      1233 non-null   object\n",
      " 50  50      1233 non-null   object\n",
      " 51  51      1233 non-null   object\n",
      " 52  52      1233 non-null   object\n",
      " 53  53      1233 non-null   object\n",
      " 54  54      1233 non-null   object\n",
      " 55  55      1233 non-null   object\n",
      " 56  56      1233 non-null   object\n",
      " 57  57      1233 non-null   object\n",
      "dtypes: object(58)\n",
      "memory usage: 568.3+ KB\n"
     ]
    }
   ],
   "source": [
    "small_df = img_link_df.dropna()\n",
    "small_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(url, headers):\n",
    "    im = loadImage(url, headers)\n",
    "#     im = Image.open(requests.get(url, stream=True).raw)\n",
    "#     im = im.resize((224, 224), Image.ANTIALIAS)\n",
    "    x = image.img_to_array(im)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = mobilenet_v2.preprocess_input(x)\n",
    "    return x\n",
    "\n",
    "def show_image(url):\n",
    "    \n",
    "    img = Image.open(requests.get(url, stream=True).raw)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "def loadImage(URL, headers):\n",
    "    response = requests.get(URL, headers=headers) \n",
    "    image_io = BytesIO(response.content)\n",
    "    img = image.load_img(image_io, target_size=(224, 224))\n",
    "\n",
    "    return img\n",
    "\n",
    "def get_predictions(url, headers, models):\n",
    "\n",
    "    x = prepare_image(url, headers)\n",
    "\n",
    "    out = model.predict(x)\n",
    "\n",
    "    df = pd.DataFrame(columns = ['prediction', 'probability'])\n",
    "    predictions = mobilenet_v2.decode_predictions(out)[0]\n",
    "    idx = 0\n",
    "    for x in predictions:\n",
    "        df = df.append(pd.DataFrame({'prediction':x[1], 'probability': x[2]}, index=[idx]), ignore_index=True)\n",
    "        idx = idx + 1\n",
    "    return df\n",
    "\n",
    "def get_predictions_dictionary(attraction_index):\n",
    "    ua = UserAgent()\n",
    "    headers = {'user-agent': ua.random}\n",
    "    \n",
    "    url_list = small_df.iloc[attraction_index]\n",
    "    preds_dict = defaultdict(int)\n",
    "    for url in url_list :\n",
    "        df = get_predictions(url, headers)\n",
    "        for index, row in df.iterrows():\n",
    "            preds_dict[row[0]] += row[1]\n",
    "\n",
    "    return preds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, while RGB values are simple to understand, the RGB color space fails to mimic how humans perceive color. \n",
    "# Instead, we are going to use the HSV color space which maps pixel intensities into a cylinder:\n",
    "\n",
    "def load_img_open_cv(url):\n",
    "#     ua = UserAgent()\n",
    "#     headers = {'user-agent': ua.random}\n",
    "\n",
    "    resp = urllib.request.urlopen(url)\n",
    "\n",
    "    image = np.array(bytearray(resp.read()), dtype = np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    \n",
    "    return image\n",
    "    \n",
    "def describe( url, bins):\n",
    "    image = load_img_open_cv(url)\n",
    "    \n",
    "    # convert the image to the HSV color space and initialize the features used to quantify the image\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    features = []\n",
    "    \n",
    "    # grab the dimensions and compute the center of the image\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (int(w * 0.5), int(h * 0.5))\n",
    "    \n",
    "    # divide the image into four rectangles/segments (top-left, top-right, bottom-right, bottom-left)\n",
    "    segments = [(0, cX, 0, cY), (cX, w, 0, cY), (cX, w, cY, h), (0, cX, cY, h)]\n",
    "    \n",
    "    # construct an elliptical mask representing the center of the image\n",
    "    (axesX, axesY) = (int(w * 0.75) // 2, int(h * 0.75) // 2)\n",
    "    ellipMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "    cv2.ellipse(ellipMask, (cX, cY), (axesX, axesY), 0, 0, 360, 255, -1)\n",
    "    \n",
    "    # loop over the segments\n",
    "    for (startX, endX, startY, endY) in segments:\n",
    "        \n",
    "        # construct a mask for each corner of the image, subtracting the elliptical center from it\n",
    "        cornerMask = np.zeros(image.shape[:2], dtype = \"uint8\")\n",
    "        cv2.rectangle(cornerMask, (startX, startY), (endX, endY), 255, -1)\n",
    "        cornerMask = cv2.subtract(cornerMask, ellipMask)\n",
    "\n",
    "        # extract a color histogram from the image, then update the feature vector\n",
    "        hist = histogram(image, cornerMask, bins)\n",
    "        features.extend(hist)\n",
    "        \n",
    "    # extract a color histogram from the elliptical region and update the feature vector\n",
    "    hist = histogram(image, ellipMask, bins)\n",
    "    features.extend(hist)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def histogram(image, mask, bins):\n",
    "    # extract a 3D color histogram from the masked region of the image, using the supplied number of bins per channel\n",
    "    hist = cv2.calcHist([image], [0,1,2], mask, [bins,bins,bins],[0, 256, 0, 256, 0, 256])\n",
    "    \n",
    "    # normalize the histogram if we are using OpenCV 2.4\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist).flatten()\n",
    "        \n",
    "    # otherwise handle for OpenCV 3+\n",
    "    else:\n",
    "        hist = cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "    return hist\n",
    "\n",
    "def plot_color_hist(url):\n",
    "    img = load_img_open_cv(url)\n",
    "    \n",
    "    color = ('b','g','r')\n",
    "    for i,col in enumerate(color):\n",
    "        histr = cv2.calcHist([img],[i],None,[256],[0,256])\n",
    "        plt.plot(histr,color = col)\n",
    "        plt.xlim([0,256])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aa075523d810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# This is all we need to load and use the full pretrained model!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMobileNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/applications/mobilenet_v2.py\u001b[0m in \u001b[0;36mMobileNetV2\u001b[0;34m(input_shape, alpha, include_top, weights, input_tensor, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    405\u001b[0m       weights_path = data_utils.get_file(\n\u001b[1;32m    406\u001b[0m           model_name, weight_path, cache_subdir='models')\n\u001b[0;32m--> 407\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2232\u001b[0m             f, self.layers, skip_mismatch=skip_mismatch)\n\u001b[1;32m   2233\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2234\u001b[0;31m         \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2236\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_updated_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m    660\u001b[0m   \"\"\"\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'keras_version'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m     \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keras_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "attr_preds_list = []\n",
    "img_preds_list = []\n",
    "img_color_list = []\n",
    "img_feats_list = []\n",
    "\n",
    "attractions = small_df.index.values\n",
    "end = 5 #len(small_df) + 1\n",
    "\n",
    "ua = UserAgent()\n",
    "headers = {'user-agent': ua.random}\n",
    "\n",
    "bins = 12\n",
    "\n",
    "# This is all we need to load and use the full pretrained model!\n",
    "model = mobilenet_v2.MobileNetV2(weights='imagenet')\n",
    "\n",
    "for x in range(0, end): \n",
    "    attr_preds_list.append(dict(get_predictions_dictionary(x))) \n",
    "    df = get_predictions(url, headers, model)\n",
    "    img_preds_list.append(df.to_dict())\n",
    "    img_feats_list.append(describe( url, bins))\n",
    "    \n",
    "df_attr_preds = pd.DataFrame(attr_preds_list)\n",
    "df_attr_preds.set_index(attractions[0:end], inplace=True)\n",
    "print(df_attr_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = small_df.iloc[225][25]\n",
    "feats = describe(url, 16)\n",
    "plot_color_hist(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
